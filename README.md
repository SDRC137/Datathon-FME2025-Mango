# Datathon-FME2025-Mango

# ü•≠ Mango Demand Forecast ‚Äì Datathon Hackathon Edition

Este repo recoge el proyecto que estamos haciendo para el reto de Mango, donde el reto es b√°sicamente responder a una pregunta muy sencilla de decir‚Ä¶ y nada sencilla de resolver:

> ¬øCu√°ntas prendas deber√≠amos producir la pr√≥xima temporada para no quedarnos cortos ni ahogarnos en stock?

La gracia del problema es que se parece much√≠simo a lo que hace Mango en la vida real:

- Tenemos **datos hist√≥ricos de varias temporadas** (Spring‚ÄìSummer y Fall‚ÄìWinter).
- Cada producto viene con:
  - **Embeddings de imagen** (la foto de la prenda convertida a n√∫meros).
  - **Familia y categor√≠a de producto** (vestidos, pantalones, abrigos, etc.).
  - **Atributos de la prenda** (mangas, cuello, silueta, tejido‚Ä¶).
  - Info de negocio como:
    - N√∫mero de **tiendas** donde se vende.
    - N√∫mero de **tallas** disponibles.
    - **Ciclo de vida** (cu√°ndo entra y cu√°ndo sale a la venta).
- Y adem√°s:
  - **Ventas semanales reales**.
  - **Producci√≥n hist√≥rica** (lo que Mango pidi√≥ al proveedor).
  - Una estimaci√≥n interna de la **demanda ‚Äúreal‚Äù** (qu√© se habr√≠a vendido con stock infinito).

El objetivo del challenge es predecir, para cada producto de la nueva temporada, una cantidad llamada `Production`, que en la pr√°ctica es:

> *‚ÄúCu√°nto deber√≠amos encargar al proveedor para cubrir la demanda sin pasarnos demasiado.‚Äù*

La evaluaci√≥n no es el t√≠pico RMSE de Kaggle, sino una m√©trica m√°s cercana al negocio:

- Se calcula a partir del ratio **VAR (Ventas Antes de Rebajas / Producci√≥n)**.
- **Quedarse corto** (no producir suficiente y perder ventas) se penaliza m√°s que **producir de m√°s** (sobrar√° stock, pero algo se puede recolocar/vender luego).
- El resultado es un score de **0 a 100**, y nuestra misi√≥n es llevarlo lo m√°s arriba posible.

En resumen:

- Es un problema de **forecasting de demanda**,
- con mezcla de **datos tabulares + visi√≥n (embeddings)**,
- y una m√©trica **asim√©trica**, muy centrada en el impacto real de negocio.

---

## üîß Proceso Implementado

### 1. Preprocesamiento de Datos

#### Limpieza inicial
- **Eliminaci√≥n de columnas con >40% de valores faltantes**: Identificamos y eliminamos columnas poco informativas que podr√≠an introducir ruido en el modelo.
- **Eliminaci√≥n de filas con valores cr√≠ticos faltantes**: Removemos productos sin `Production` o `image_embedding`, ya que son esenciales para el entrenamiento.

#### Agregaci√≥n por ID
- Agrupamos las ventas semanales por producto (`ID`) para obtener m√©tricas agregadas:
  - `total_demand`: Suma de la demanda semanal
  - `total_sales`: Suma de las ventas semanales
  - `sell_through`: Ratio de ventas sobre producci√≥n (indicador de stockout)
  - `is_stockout`: Flag binario para productos con sell-through ‚â• 0.98

#### Feature engineering
- **Variables temporales**: Extracci√≥n de mes y semana del a√±o desde `phase_in`.
- **One-Hot Encoding**: Codificaci√≥n de todas las variables categ√≥ricas (familia, categor√≠a, fabric, color, silhouette, etc.).
- **Escalado de variables num√©ricas**: Normalizaci√≥n con `StandardScaler` de las features num√©ricas continuas (excluyendo variables binarias one-hot encoded).
- **Limpieza de nombres**: Eliminaci√≥n de caracteres especiales en nombres de columnas para compatibilidad con LightGBM.

### 2. Modelo: LightGBM

Utilizamos **LightGBM Regressor** con los siguientes par√°metros:

```python
lgbm_params = {
    'objective': 'regression_l1',  # MAE como funci√≥n de p√©rdida
    'metric': 'mae',
    'n_estimators': 115,  # N√∫mero √≥ptimo de √°rboles
    'learning_rate': 0.05,
    'n_jobs': -1,
    'random_state': 42,
    'verbose': -1
}
```

**Caracter√≠sticas del modelo:**
- Entrenamiento con el 100% de los datos disponibles
- Funci√≥n de p√©rdida: MAE (Mean Absolute Error)
- One-hot encoding de categ√≥ricas (no usamos el manejo nativo de categ√≥ricas de LightGBM)
- Features totales: ~200+ (incluyendo one-hot encoded)

### 3. Generaci√≥n de Submissions

Generamos m√∫ltiples archivos de submission aplicando diferentes **factores de riesgo** a las predicciones base:
- `intento_1`: factor 30x
- `intento_2`: factor 20x
- `intento_3`: factor 25x

Esto nos permite explorar diferentes niveles de conservadurismo en la producci√≥n.

---

## üìä Resultados

**Score obtenido: 32.69%**

Este score refleja el desempe√±o en la m√©trica VAR (Ventas Antes de Rebajas / Producci√≥n) evaluada por la competici√≥n.

---

## üîç Posibles Mejoras

### Sobreentrenamiento detectado
Creemos que el modelo est√° **sobreajustando los datos de entrenamiento**. Posibles acciones:

1. **Regularizaci√≥n m√°s agresiva**: 
   - Aumentar `min_child_samples`
   - Reducir `max_depth`
   - Aumentar `reg_alpha` y `reg_beta`

2. **Validaci√≥n cruzada temporal**: 
   - Implementar un esquema de validaci√≥n que respete el orden temporal de las temporadas
   - Usar TimeSeriesSplit para evaluar el modelo de forma m√°s robusta

3. **Feature selection**: 
   - Analizar importancia de features y eliminar las menos relevantes
   - Reducir la dimensionalidad del one-hot encoding agrupando categor√≠as poco frecuentes

4. **Early stopping**: 
   - Implementar early stopping con un validation set separado
   - Monitorear la curva de aprendizaje para detectar overfitting

5. **Ensemble con otros modelos**: 
   - Probar XGBoost, CatBoost o modelos lineales
   - Combinar predicciones mediante stacking o blending